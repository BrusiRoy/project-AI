Result for the XGBClassifier on the MNIST dataset with the following specification:
XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,
       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1)Classification Report:
             precision    recall  f1-score   support

        0.0       0.96      0.98      0.97       660
        1.0       0.95      0.97      0.96       779
        2.0       0.93      0.93      0.93       688
        3.0       0.93      0.91      0.92       733
        4.0       0.93      0.93      0.93       640
        5.0       0.94      0.90      0.92       651
        6.0       0.96      0.96      0.96       738
        7.0       0.94      0.94      0.94       724
        8.0       0.92      0.91      0.92       672
        9.0       0.89      0.90      0.90       715

avg / total       0.93      0.93      0.93      7000
Confusion matrix:
[[646   0   1   2   1   1   3   1   5   0]
 [  0 755   7   7   0   1   1   0   7   1]
 [  3   3 637   5   5   0  12  10  12   1]
 [  0   9  16 664   2  12   3   8  10   9]
 [  4   1   0   1 594   2   4   2   4  28]
 [  4   3   6  18   3 587   4   2  13  11]
 [  5   3   2   0   5  10 712   0   1   0]
 [  3   0  11   2   6   0   0 681   0  21]
 [  2  14   6   8   1   7   6   4 613  11]
 [  6   5   1  10  24   6   0  15   1 647]]
Execution time: 1674.3422632217407